# ğŸ“˜ Explicabilidad y AnÃ¡lisis Ã‰tico en Modelos Predictivos (XAI)

Este proyecto aplica tÃ©cnicas de *Explainable Artificial Intelligence (XAI)* para analizar la transparencia, sesgos y comportamiento de modelos supervisados entrenados sobre un conjunto de datos real de mantenimiento predictivo.
Incluye evaluaciÃ³n de calidad de datos, explicaciÃ³n de modelos, detecciÃ³n de sesgos y recomendaciones Ã©ticas.

---

## ğŸ“Œ 1. Objetivo del Proyecto

- Implementar un modelo de ML considerando calidad de datos y mitigaciÃ³n de sesgos.
- Aplicar tÃ©cnicas de explicabilidad: **SHAP**, **Permutation Importance**, **Ãrboles de decisiÃ³n**, etc.
- Analizar transparencia del modelo y cÃ³mo toma decisiones.
- Detectar riesgos Ã©ticos y sociales.
- Documentar correctamente el proceso completo.

---

## ğŸ“‚ 2. Estructura del Repositorio

ğŸ“ data/ â†’ Dataset original
ğŸ“ src/ â†’ CÃ³digo fuente (preprocesamiento, entrenamiento, XAI)
ğŸ“ notebooks/ â†’ Notebooks de anÃ¡lisis
ğŸ“ figures/ â†’ GrÃ¡ficos exportados
ğŸ“ results/ â†’ MÃ©tricas, explicaciones y conclusiones
README.md â†’ Documento principal


---

## ğŸ“Š 3. AnÃ¡lisis Exploratorio del Dataset

Se analizaron variables como:

- Edad
- Ingresos
- Nivel educativo
- Zona geogrÃ¡fica
- Historial crediticio
- Estado civil
- Sexo
- OcupaciÃ³n
- Resultado de crÃ©dito anterior

Incluyendo:

- Distribuciones
- Boxplots
- Correlaciones
- IdentificaciÃ³n de desbalances

Las figuras se encuentran en:
ğŸ“ `figures/heatmap_correlations.png`
ğŸ“ `figures/kmeans_pca.png`
ğŸ“ `figures/dbscan_pca.png`

---

## ğŸ¤– 4. Entrenamiento del Modelo Supervisado

Se entrenaron los siguientes modelos:

- **Random Forest (modelo principal)**
- RegresiÃ³n LogÃ­stica
- Ãrbol de DecisiÃ³n
- SVM (opcional)

Con tÃ©cnicas de:

- Balanceo (`class_weight='balanced'`)
- NormalizaciÃ³n / escalamiento
- CodificaciÃ³n de variables categÃ³ricas

Resultados principales almacenados en:

ğŸ“ `results/metrics.txt`
ğŸ“ `results/feature_importance.png`

---

## ğŸ§  5. Explicabilidad del Modelo (XAI)

Se aplicaron las siguientes tÃ©cnicas:

### âœ” SHAP Values
- Summary Plot
- Force Plot por instancia
- Ranking de variables

ğŸ“ `figures/shap_summary.png`
ğŸ“ `figures/shap_force_example.png`

### âœ” Permutation Feature Importance
ğŸ“ `figures/permutation_importance.png`

### âœ” VisualizaciÃ³n del Ãrbol de DecisiÃ³n
ğŸ“ `figures/decision_tree.png`

Cada tÃ©cnica muestra quÃ© variables influyen mÃ¡s en la clasificaciÃ³n y cÃ³mo afectan la predicciÃ³n.

---

## âš ï¸ 6. IdentificaciÃ³n de Sesgos AlgorÃ­tmicos

Se evaluaron sesgos por:

- GÃ©nero
- Zona geogrÃ¡fica
- Edad
- Ingresos

Se detectaron diferencias significativas en:

- Tasas de aprobaciÃ³n para mujeres jÃ³venes
- VariaciÃ³n por zona geogrÃ¡fica
- Efecto del historial crediticio

Los anÃ¡lisis se encuentran en:

ğŸ“ `results/bias_analysis.txt`
ğŸ“ `figures/bias_gender.png`
ğŸ“ `figures/bias_zone.png`

---

## ğŸ›¡ï¸ 7. Propuestas de MitigaciÃ³n

- RecolecciÃ³n de datos mÃ¡s representativos.
- EliminaciÃ³n/codificaciÃ³n Ã©tica de variables sensibles.
- Reentrenamiento con tÃ©cnicas de fairness.
- Ajuste de umbrales por grupo.
- Monitoreo continuo del sistema.

---

## ğŸ“Œ 8. Conclusiones

- El modelo presenta **sesgo detectado en gÃ©nero y zona**, que debe mitigarse antes de su uso real.
- Las tÃ©cnicas XAI permitieron identificar **quÃ© variables dominan la decisiÃ³n**, destacando historial crediticio, temperatura del proceso y torque.
- La integraciÃ³n de XAI mejora la transparencia del sistema y permite una auditorÃ­a Ã©tica responsable.
- Se recomienda implementar estrategias de fairness y validar periÃ³dicamente su comportamiento.

---

## ğŸ‘¨â€ğŸ’» Autor
Angel Yambay M
